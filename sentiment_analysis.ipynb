{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-anchor",
   "metadata": {},
   "source": [
    "## Llamada a la API para obtener todos los dialogos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:5000/\"\n",
    "#GET\n",
    "\n",
    "endpoint_user = \"users\"\n",
    "endopoint_message= \"messages\"\n",
    "endopoint_user_message= \"<episode>/<name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = requests.get(url + endopoint_message).json()\n",
    "mess[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-contest",
   "metadata": {},
   "source": [
    "### Hacemos un dataframe con ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-provision",
   "metadata": {},
   "source": [
    "### Aplicamos Stop Words de NLTK para deshacernos de las palabras neutras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Line\"] = data[\"Line\"].astype(str)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Line = data.Line.apply(lambda x: x.split(\" \"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words (lista):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    nueva_lista = []\n",
    "    for string in lista:\n",
    "        if string.lower() not in stop_words:\n",
    "            nueva_lista.append(string)\n",
    "    return \" \".join(nueva_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Line = data.Line.apply(stop_words)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-logging",
   "metadata": {},
   "source": [
    "## Realizamos Sentiment Analysis con Vader Lexicon de NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(sentence):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    polarity = sia.polarity_scores(sentence)\n",
    "    pol = polarity['compound']\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment_compound'] = data.Line.apply(sentimentAnalysis)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = data.groupby(['Character'])['sentiment_compound'].mean().sort_values()\n",
    "#resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_5 = resumen[:5]\n",
    "tail_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-receiver",
   "metadata": {},
   "source": [
    "### Darryl es quien obtiene la peor puntuación al analizar los 3 primeros capitulos de la temporada 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_5.plot(kind=\"bar\", color= \"lightcoral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = resumen[-5:]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-tenant",
   "metadata": {},
   "source": [
    "### Townsfolf es quien obtiene la mejor puntuación al analizar los 3 primeros capitulos de la temporada 10. Entendemos que el Speaker es el narrador de los capitulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5.plot(kind=\"bar\", color = \"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-radius",
   "metadata": {},
   "source": [
    "## Creamos dataframe solo con los 4 protagonistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = pd.DataFrame(resumen)\n",
    "#resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen['protas'] = resumen.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen2 = resumen[(resumen[\"protas\"]== \"Cartman\")| (resumen[\"protas\"]== \"Kenny\") | (resumen[\"protas\"]== \"Kyle\") | (resumen[\"protas\"]== \"Stan\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-cleveland",
   "metadata": {},
   "source": [
    "### Todos los protagonistas obtienen un analisis neutro, todos los valores muy ceca del cero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = resumen2[\"protas\"],\n",
    "    y = resumen2[\"sentiment_compound\"],\n",
    "    palette= \"PRGn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-explanation",
   "metadata": {},
   "source": [
    "### Analisis con WordCloud para ver cuales son las palabras más utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protas = data[(data[\"Character\"]== \"Cartman\")| (data[\"Character\"]== \"Kenny\") | (data[\"Character\"]== \"Kyle\") | (data[\"Character\"]== \"Stan\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWordCloud(data,title):\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "        colormap= 'Set2',\n",
    "        max_words=500,\n",
    "        max_font_size=50, \n",
    "        scale=5,\n",
    "        random_state=3).generate(str(data))\n",
    "\n",
    "\n",
    "    wordcloud.recolor(random_state=1)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.title(title, fontsize=20,color='black')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    " generateWordCloud(df_protas['Line'],\"Word Cloud Season 10.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
